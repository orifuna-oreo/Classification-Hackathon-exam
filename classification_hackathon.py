{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [markdown]\n# # Language Identification in South African Text: Kaggle Competition\n\n# %% [markdown]\n# ## Importing necessary libraries\n\n# %% [code]\n# Importing necessary libraries! \nimport pandas as pd\nimport numpy as np\nimport re\nimport string\nfrom sklearn.feature_extraction.text import CountVectorizer \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \nfrom sklearn.metrics import f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\n\n\n# %% [code]\n!pip install nlppreprocess \n\n# %% [markdown]\n# ## Loading the data\n\n# %% [code]\ntrain = pd.read_csv('/kaggle/input/south-african-language-identification-hack-2023/train_set.csv')\ntest = pd.read_csv('/kaggle/input/south-african-language-identification-hack-2023/test_set.csv')\n\n# %% [markdown]\n# ## Exploratory Data Analysis (EDA)\n\n# %% [code]\ntrain.head(5)\n\n# %% [code]\ntrain.shape\n\n# %% [code]\ntrain.info\n\n# %% [code]\ntrain.isnull().sum() \n\n# %% [code]\ntrain.duplicated().sum()\n\n# %% [code]\ntrain = train.drop_duplicates() \n\n# %% [code]\ntrain.shape\n\n# %% [code]\ntrain['lang_id'] .unique()\n\n# %% [code]\ndef clean(text):\n text = str(text).lower()\n text = re.sub('\\[.*?\\]', '', text)\n text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n text = re.sub('<.*?>+', '', text)\n text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n text = re.sub('\\n', '', text)\n text = re.sub('\\w*\\d\\w*', '', text)\n text =\" \".join(text)\n return text\ntrain[\"text\"] = train[\"text\"].apply(clean)\ntest[\"text\"] =test[\"text\"].apply(clean) \n\n# %% [code]\ntrain['lang_id'].value_counts()\n\n# %% [markdown]\n# ## Data Preprocessing\n\n# %% [code]\nimport nltk\nnltk.download('stopwords')\n\n# %% [code]\nfrom nlppreprocess import NLP\nnlp = NLP()\nnlp.process('couldnt')\n\n# %% [code]\ntrain.head() \n\n# %% [code]\n#Removing the Stopwords\nstopword = nltk.corpus.stopwords.words('english')\ndef remove_stopwords(x):\n    stopwords = NLP(replace_words=True, remove_stopwords=True, \n                            remove_numbers=True) \n    x = stopwords.process(x)\n    return x\n\n# %% [code]\ntrain['text'] = train['text'].apply(lambda x:remove_stopwords(x)) \n\n# %% [code]\n#splitting the data \nX = train['text'] \ny = train ['lang_id'] \n\n# %% [code]\ntrain.head()\n\n# %% [markdown]\n# ## Preprocessing the data\n\n# %% [code]\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ndef preprocess_data(train, test):\n    # Initializing the TF-IDF vectorizer\n    vectorizer = TfidfVectorizer(stop_words='english', analyzer='char')\n    # Fitting the vectorizer on the training data\n    vectorizer.fit(train['text'])\n    # Transforming the training and test data using the fitted vectorizer\n    train_features = vectorizer.transform(train['text'])\n    test_features = vectorizer.transform(test['text'])\n    return train_features, test_features, vectorizer\n# Assuming you have 'train' and 'test' DataFrames\ntrain_features, test_features, vectorizer = preprocess_data(train, test)\n\n\n# %% [markdown]\n# ## Training and Evaluation\n\n# %% [markdown]\n# ### Logistic Regression\n\n# %% [code]\nX_train, X_test, y_train, y_test = train_test_split(train_features, train['lang_id'], test_size=0.2, random_state=42)\nlr_model = LogisticRegression()\nlr_model.fit(X_train, y_train)\nlr_preds = lr_model.predict(X_test)\nlr_f1 = f1_score(y_test, lr_preds, average='weighted')\n\nprint(\"Logistic Regression F1 Score:\", lr_f1)\n\n\n# %% [markdown]\n# ### K Nearest Neighbors (KNN)\n\n# %% [code]\nknn_model = KNeighborsClassifier()\nknn_model.fit(X_train, y_train)\nknn_preds = knn_model.predict(X_test)\nknn_f1 = f1_score(y_test, knn_preds, average='weighted')\n\nprint(\"KNN F1 Score:\", knn_f1)\n\n\n# %% [markdown]\n# ### Support Vector Machine\n\n# %% [code]\nsvm = SVC()\nsvm.fit(X_train, y_train)\nsvm_predictions = svm.predict(X_test)\nsvm_f1 = f1_score(y_test, svm_predictions, average='weighted')\nprint(\"SVM F1 Score:\", svm_f1)\n\n# %% [markdown]\n# ### Naive Bayes\n\n# %% [code]\nnb = MultinomialNB()\nnb.fit(X_train, y_train)\nnb_predictions = nb.predict(X_test)\nnb_f1 = f1_score(y_test, nb_predictions, average='weighted')\nprint(\"Naive Bayes F1 Score:\", nb_f1)\n\n\n# %% [markdown]\n# ## Generate predictions on the test set\n\n# %% [code]\n# Converting the test data into TF-IDF vectors\nX_test = vectorizer.transform(test['text'])\n\n# Generating predictions on the best performing model\ntest_predictions = svm.predict(X_test)\n\n# %% [markdown]\n# ## Creating a csv for submission\n\n# %% [code]\n# Creating a submission dataframe with 'index' and 'lang_id' columns\nsubmission_df = pd.DataFrame({'index': test['index'], 'lang_id': test_predictions})\n\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"_uuid":"9a917eba-b84f-47d2-bd2c-df9e0628f814","_cell_guid":"6a158f38-3f45-47ad-8cd9-832edc9d6662","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}